{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63327603",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ed9ed8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import preprocessor as p\n",
    "import emojis\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a3faa",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21ebdc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(twitter_data):\n",
    "    \n",
    "    #load data \n",
    "    data = pd.read_csv(twitter_data)\n",
    "    \n",
    "    #print the dataset shape\n",
    "    print('The number of tweets:\\n{}\\n\\n'.format(data.shape[0]))\n",
    "    \n",
    "    #the feature of the data set are\n",
    "    print('The features or columns in our dataset are {}'.format(list(data.columns)))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc2dccc",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "230ec27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(data):    \n",
    "    \n",
    "    #Print the number of tweets with hate language\n",
    "    print('The number of hate tweets:\\n{}\\n\\n'.format(data[data['label'] == 1].shape[0]))\n",
    "    \n",
    "    #the percentage of tweets with hate language\n",
    "    print('The percentage of hate tweets:\\n{}\\n\\n'.format((data[data['label']==1].shape[0]/data.shape[0])*100))\n",
    "    \n",
    "    #print the number of tweets without hate language\n",
    "    print('The number of tweets not classified as hate tweets:\\n{}\\n\\n'.format(data[data['label']==0].shape[0]))\n",
    "    \n",
    "    #the percentage of tweets without language\n",
    "    print('The percentage of tweets without hate language:\\n{}\\n\\n'.format((data[data['label']==0].shape[0]/data.shape[0])*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd62685",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5eb08b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove alphanumeric and lower\n",
    "def text_preprocessing(text,index,column,data):\n",
    "    \n",
    "    if type(text) is not int:\n",
    "        strng = \"\"\n",
    "        for words in text.split():\n",
    "            \n",
    "            #removing special characters \n",
    "            word = (\"\".join(i for i in words if i.isalnum()))\n",
    "            \n",
    "            #lowering the words\n",
    "            word = word.lower()\n",
    "            \n",
    "            strng += word + \" \"\n",
    "            \n",
    "        data[column][index] = strng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd524d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis(text):\n",
    "    text = emojis.decode(text)\n",
    "    text = text.replace(\":\",\" \")\n",
    "    text  = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87647717",
   "metadata": {},
   "outputs": [],
   "source": [
    "SMILEYS = {\":‑(\":\"sad\", \":‑(\":\"sad\", \":(\":\"sad\",\":‑c\":\"sad\",\":c\":\"sad\",\":‑<\":\"sad\",\":<\":\"sad\",\":‑[\":\"sad\",\":[\":\"sad\",\":-||\":\"sad\",\">:[\":\"sad\",\":{\":\"sad\",\":@\":\"sad\",\":(\t\":\"sad\",\";( \":\"sad\",\":‑)\":\"happy\", \":‑D\" : \"laughing\", \"8D\":\"laughing\" , \"x‑D\": \"laughing\", \"xD\": \"laughing\",\"X‑D\": \"laughing\",\n",
    "\"XD\": \"laughing\",\"=D\": \"laughing\", \"=3\": \"laughing\", \"B^D\": \"laughing\" , \"c:\" : \"laughing\", \":-]\":\"happy\",\":]\": \"happy\",\":-3\": \"happy\", \":3\":\"happy\", \":->\": \"happy\",\":>\": \"happy\", \"8-)\": \"happy\",\"8)\": \"happy\",\":-}\": \"happy\",\":}\": \"happy\",\":o)\": \"happy\",\":c\": \"happy\" , \":^)\": \"happy\",\"=]\": \"happy\", \"=)\": \"happy\",\n",
    "\":‑###..\":\"being sick\",\":###..\":\"being sick\",\"',:-|\":\"disbelief\",\"',:-l\":\"disbelief\",\">:‑)\":\"Evil\",\"}:‑)\":\"Evil\",\"}:)\":\"Evil\",\"3:‑)\":\"Evil\",\"3:)\":\"Evil\",\">;)\":\"Evil\",\";3\":\"Evil\",\"D‑':\":\"horror\"}\n",
    "\n",
    "def convert_emoticons(text):\n",
    "    words = text.split()\n",
    "    reformed = [SMILEYS[word] if word in SMILEYS else word for word in words]\n",
    "    text = \" \".join(reformed)\n",
    "    return text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f585802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    \n",
    "    #removing null labels\n",
    "    data = data[~data['label'].isnull()]\n",
    "    print('The number of data point remaining after removing all null labels:\\n{}\\n\\n'.format(data.shape[0]))\n",
    "    \n",
    "    #removing duplicate tweets\n",
    "    data = data[~data['tweet'].duplicated()]\n",
    "    print(' the number of data point remaning after removing all duplicate tweets:\\n{}\\n\\n'.format(data.shape[0]))\n",
    "    \n",
    "    #cleaning the data according to our needa\n",
    "    for i in data.index:    \n",
    "        #removing the urls and \n",
    "        p.set_options(p.OPT.URL)\n",
    "        tweet = p.clean(data['tweet'].loc[i])\n",
    "\n",
    "        #removing punctuations\n",
    "        tweet = ' '.join(re.sub(\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
    "\n",
    "        #conversion of emojis\n",
    "        tweet = convert_emojis(tweet)\n",
    "\n",
    "        #conversion of emoticons\n",
    "        tweet = convert_emoticons(tweet)\n",
    "\n",
    "        #removing the remaining emoticons and numbers data in text\n",
    "        p.set_options(p.OPT.EMOJI,p.OPT.NUMBER)\n",
    "        tweet = p.clean(tweet)\n",
    "\n",
    "        #removing the alphanumeric variables in text and lowering texts \n",
    "        text_preprocessing(tweet,i,'tweet',data)\n",
    "        \n",
    "    #printing the processed tweet\n",
    "    print('The tweet text data is processed{}'.format(data['tweet']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aff77758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(Twitter_data):\n",
    "    \n",
    "        print('LOADING DATA...{}\\n\\n '.format(Twitter_data))\n",
    "        data = load_data(Twitter_data)\n",
    "\n",
    "        print('DATA ANALYSIS...\\n\\n')\n",
    "        analysis(data)\n",
    "        \n",
    "        print('CLEANING DATA...\\n\\n')\n",
    "        data = data_cleaning(data)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6601274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATA...train.csv\n",
      "\n",
      " \n",
      "The number of tweets:\n",
      "31962\n",
      "\n",
      "\n",
      "The features or columns in our dataset are ['id', 'label', 'tweet']\n",
      "DATA ANALYSIS...\n",
      "\n",
      "\n",
      "The number of hate tweets:\n",
      "2242\n",
      "\n",
      "\n",
      "The percentage of hate tweets:\n",
      "7.014579813528565\n",
      "\n",
      "\n",
      "The number of tweets not classified as hate tweets:\n",
      "29720\n",
      "\n",
      "\n",
      "The percentage of tweets without hate language:\n",
      "92.98542018647143\n",
      "\n",
      "\n",
      "CLEANING DATA...\n",
      "\n",
      "\n",
      "The number of data point remaining after removing all null labels:\n",
      "31962\n",
      "\n",
      "\n",
      " the number of data point remaning after removing all duplicate tweets:\n",
      "29530\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-67-449fad1c34c4>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[column][index] = strng\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweet text data is processed0        user when a father is dysfunctional and is so ...\n",
      "1        user user thanks for lyft credit i cant use ca...\n",
      "2                                     bihday your majesty \n",
      "3           model i love u take with u all the time in ur \n",
      "4                       factsguide society now motivation \n",
      "                               ...                        \n",
      "31956    off fishing tomorrow user carnt wait first tim...\n",
      "31957                             ate user isz that youuu \n",
      "31958    to see nina turner on the airwaves trying to w...\n",
      "31959    listening to sad songs on a monday morning otw...\n",
      "31961                       thank you user for you follow \n",
      "Name: tweet, Length: 29530, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = main('train.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
